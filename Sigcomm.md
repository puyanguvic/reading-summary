## 2022' Stateful Multi-Pipelined Programmable Switches
Given the clock rate of a single packet processing pipeline has saturated due to slowdown in transistor scaling, today‚Äôs programmable switches employ multiple parallel pipelines to meet high packet processing rates. However, parallel processing poses a challenge for stateful packet processing, where it becomes hard to guarantee functional correctness while maintaining line rate processing. This paper presents the design and implementation of MP5, which is a new switch architecture, compiler, and runtime for multi-pipelined programmable switches that is functionally equivalent to a logical single pipelined switch while also processing packets close to the ideal processing rate, for all packet processing programs.

**Main idea** multi-pipelined programmable switch processing pipeline that achieves the following two goals.
‚Ä¢ Correctness. The multi-pipelined switch is functionally equivalent to the single pipelined switch.
‚Ä¢ Performance. The multi-pipelined switch processes packets as close to line rate (i.e., ùëÅ‚àóùêµ) as theoretically possible for a given packet processing program and stream of input packets, without compromising on correctness.

It is a P4 and Domino following work in SDN control plane, to improve the packet processing rate.


## 2021' Programmable Packet Scheduling with a Single Queue
Programmable packet scheduling enables scheduling algorithms to be programmed into the data plane without changing the hardware. Existing proposals either have no hardware implementations for switch ASICs or require multiple strict-priority queues. We present Admission-In First-Out (AIFO) queues, a new solution for programmable packet scheduling that uses only a single first-in first-out queue. AIFO is motivated by the confluence of two recent trends: shallow buffers in switches and fast-converging congestion control in end hosts, that together leads to a simple
observation: the decisive factor in a flow‚Äôs completion time (FCT) in modern datacenter networks is often which packets are enqueued or dropped, not the ordering they leave the switch. The core idea of AIFO is to maintain a sliding window to track the ranks of recent packets and compute the relative rank of an arriving packet in the window for admission control. Theoretically, we prove that AIFO provides bounded performance to Push-In First-Out (PIFO). Empirically, we fully implement AIFO and evaluate AIFO with a range of real workloads, demonstrating AIFO closely approximates PIFO. Importantly, unlike PIFO, AIFO can run at line rate on existing hardware and use minimal switch resources‚Äîas few as a single queue.

**Main idea** AIFO is a new approach to programmable packet scheduling that uses only a single queue. AIFO computes a rank quantile for a coming packet and decides whether to admit the packet into the queue based on the rank qunatile and the queue length. It based on slicing window to adjust the packet order and give the first prioiry to the high rank packets.

## 2020' Routing on Multiple Optimality Criteria
Standard vectoring protocols, such as EIGRP, BGP, DSDV, or Babel, only route on optimal paths when the total order on path attributes that substantiates optimality is consistent with the extension operation that calculates path attributes from link attributes, leaving out many optimality criteria of practical interest. We present a solution to this problem and, more generally, to the problem of routing on multiple optimality criteria. A key idea is the derivation of a partial order on path attributes that is consistent with the extension operation and respects every optimality criterion of a designated collection of such criteria. We design new vectoring protocols that compute on partial orders, with every node capable of electing multiple attributes per destination rather than a single attribute as in standard vectoring protocols. Our evaluation over publicly available network topologies and attributes shows that the proposed protocols converge fast and enable optimal path routing concurrently for many optimality criteria with only a few elected attributes at each node per destination. We further show how predicting computations on partial orders allows incorporation of service chain constraints on optimal path routing.

## 2017' NFVnice: Dynamic backpressure and scheduling for NFV service chains
Managing Network Function (NF) service chains requires careful system resource management. We propose NFVnice, a user space NF scheduling and service chain management framework to provide fair, efficient and dynamic resource scheduling capabilities on Network Function Virtualization (NFV) platforms. The NFVnice framework monitors load on a service chain at high frequency (1000Hz) and employs backpressure to shed load early in the service chain, thereby preventing wasted work. Borrowing concepts such as rate proportional scheduling from hardware packet schedulers, CPU shares are computed by accounting for heterogeneous packet processing costs of NFs, I/O, and traffic arrival characteristics. By leveraging cgroups, a user space process scheduling abstraction exposed by the operating system, NFVnice is capable of controlling when network functions should be scheduled. NFVnice improves NF performance by complementing the capabilities of the OS scheduler but without requiring changes to the OS‚Äôs scheduling mechanisms. Our controlled experiments show that NFVnice provides the appropriate rate-cost proportional fair share of CPU to NFs and significantly improves NF performance (throughput and loss) by reducing wasted work across an NF chain, compared to using the default OS scheduler. NFVnice achieves this even for heterogeneous NFs with vastly different computational costs and for heterogeneous workloads.

## 2016' Packet Transactions: High-Level Programming for Line-Rate Switches
We present the design, implementation, and evaluation of CONGA, a network-based distributed congestion-aware load balancing mechanism for datacenters. CONGA exploits recent trends including
the use of regular Clos topologies and overlays for network virtualization. It splits TCP flows into flowlets, estimates real-time congestion on fabric paths, and allocates flowlets to paths based on feedback from remote switches. This enables CONGA to efficiently balance load and seamlessly handle asymmetry, without requiring any TCP modifications. CONGA has been implemented in custom ASICs as part of a new datacenter fabric. In testbed experiments, CONGA has 5√ó better flow completion times than ECMP even with a single link failure and achieves 2‚Äì8√ó better throughput than MPTCP in Incast scenarios. Further, the Price of Anarchy for CONGA is provably small in Leaf-Spine topologies; hence CONGA is nearly as effective as a centralized scheduler while being able to react to congestion in microseconds. Our main thesis is that datacenter fabric load balancing is best done in the network, and requires global schemes such as CONGA to handle asymmetry

## 2014' CONGA: Distributed Congestion-Aware Load Balancing for Datacenters

## 2013' B4: Experience with a Globally-Deployed Software Defined WAN
**Abstract** We present the design, implementation, and evaluation of B4, a private WAN connecting Google‚Äôs data centers across the planet. B4 has a number of unique characteristics: i) massive bandwidth requirements deployed to a modest number of sites, ii) elastic traffic demand that seeks to maximize average bandwidth, and iii) full control over the edge servers and network, which enables rate limiting and demand measurement at the edge. These characteristics led to a Software Defined Networking architecture using OpenFlow to control relatively simple switches built from merchant silicon. B4‚Äôs centralized traffic engineering service drives links to near 100% utilization, while splitting application allows among multiple paths to balance capacity against application priority/demands. We describe experience with three years of B4 production deployment, lessons learned, and areas for future work.

Main idea: B4 is Google's private software-defined WAN. It works in date center network, the topology is hierarchical. And centralized linear programming (LP) traffic engineering can be used to provide flow-level traffic control.

## 2003' Routing Using Potentials: A Dynamic Traffic-Aware Routing Algorithm
We present a routing paradigm called PB-routing that utilizes steepest gradient search methods to route data packets. More specifically, the PB-routing paradigm assigns scalar potentials to network elements and forwards packets in the direction of maximum positive force. We show that the family of PB-routing schemes is loop-free and that the standard shortest path routing algorithms are a special case of the PB-routing paradigm. We then show how to design a potential function that accounts for traffic conditions at a node. The resulting routing algorithm routes around congested areas while preserving the key desirable properties of IP routing mechanisms including hop-by-hop routing, local route computations, and statistical multiplexing. Our simulations using the ns simulator indicate that the traffic-aware routing algorithm shows significant improvements in end-to-end delay and jitter when compared to standard shortest-path routing algorithms. The simulations also indicate that our algorithm does not incur too much control overheads and is fairly stable even when traffic conditions are dynamic.

**Main idea:** This traffic-aware routing is based on the steepest gradient search methods. In this work, the queue length information is assumed instantaneously available at all nodes whenever a change occurs.

**Limitations:** 
1. If the network topology is sparsely connected, this algorithm does not perform any better than OSFF.
2. The queue length of all the nodes could not be get instantaneously.
3. When congestion happened in the bottleneck link. This algorithm could not do anything.
